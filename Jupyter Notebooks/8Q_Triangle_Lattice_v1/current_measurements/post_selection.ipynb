{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\mattm\\OneDrive\\Desktop\\Research\\Projects\\Triangle Lattice\\Jupyter Notebooks\\8Q_Triangle_Lattice_v1\")\n",
    "\n",
    "import correlation_measurements.src_correlation_measurement\n",
    "importlib.reload(correlation_measurements.src_correlation_measurement)\n",
    "from correlation_measurements.src_correlation_measurement import RampOscillationShotsMeasurement, generate_ramp_double_jump_correlations_filename\n",
    "\n",
    "import src.src_current_measurement\n",
    "importlib.reload(src.src_current_measurement);\n",
    "from src.src_current_measurement import CurrentMeasurementCalibration, generate_current_calibration_filename, acquire_data, generate_ramp_beamsplitter_correlations_filename, generate_ramp_beamsplitter_correlations_clean_filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_select_counts(measurement, readout_pair_1, readout_pair_2, post_select=True):\n",
    "     ### plot post selected data\n",
    "\n",
    "    counts = measurement.get_counts()\n",
    "    times = measurement.get_times()\n",
    "\n",
    "    num_qubits = measurement.get_num_qubits()\n",
    "    num_particles = 4\n",
    "\n",
    "\n",
    "    bitstrings = list(product([0,1], repeat=num_qubits))\n",
    "    bitstrings_n_particles = []\n",
    "\n",
    "    counts_n_particles = []\n",
    "    for i, bitstring in enumerate(bitstrings):\n",
    "        if sum(bitstring) == num_particles or not post_select:\n",
    "            bitstrings_n_particles.append(bitstring)\n",
    "            counts_n_particles.append(counts[i, :])\n",
    "\n",
    "    counts_n_particles = np.array(counts_n_particles, dtype=float)\n",
    "    counts_n_particles_average = np.array(counts_n_particles, dtype=float)\n",
    "\n",
    "    for j in range(counts_n_particles_average.shape[-1]):\n",
    "        counts_n_particles_average[:,j] = counts_n_particles_average[:,j] / np.sum(counts_n_particles_average[:,j])\n",
    "\n",
    "    counts_n_particles_average = np.array(counts_n_particles, dtype=float)\n",
    "    counts_n_particles_average /= np.sum(counts_n_particles_average, axis=0)\n",
    "\n",
    "    \n",
    "    populations_post_selected = np.zeros((num_qubits, counts_n_particles_average.shape[-1]))\n",
    "    for i in range(len(bitstrings_n_particles)):\n",
    "        for j in range(num_qubits):\n",
    "            if bitstrings_n_particles[i][j] == 1:\n",
    "                populations_post_selected[j, :] += counts_n_particles_average[i, :]\n",
    "\n",
    "    total_population = np.sum(populations_post_selected, axis=0)\n",
    "\n",
    "    population_differences_post_selected = np.zeros((4, counts_n_particles.shape[-1]))\n",
    "    population_differences_post_selected[0, :] = populations_post_selected[readout_pair_1[1], :] - populations_post_selected[readout_pair_1[0], :]\n",
    "    population_differences_post_selected[1, :] = populations_post_selected[readout_pair_2[1], :] - populations_post_selected[readout_pair_2[0], :]\n",
    "\n",
    "    return populations_post_selected, counts_n_particles, bitstrings_n_particles, \n",
    "\n",
    "def get_post_selected_covariance(measurement, populations_post_selected, counts_n_particles, bitstrings_n_particles, readout_pair_1, readout_pair_2, plot_individual_terms=False):\n",
    "\n",
    "    times = measurement.get_times()\n",
    "\n",
    "    covariance_post_selected = np.zeros((8, 8, counts_n_particles.shape[-1]))\n",
    "\n",
    "    for i in range(len(bitstrings_n_particles)):\n",
    "        for index_1 in range(covariance_post_selected.shape[0]):\n",
    "            for index_2 in range(index_1, covariance_post_selected.shape[1]):\n",
    "                if bitstrings_n_particles[i][index_1] == 1 and bitstrings_n_particles[i][index_2] == 1:\n",
    "                    covariance_post_selected[index_1, index_2, :] += counts_n_particles[i, :]/np.sum(counts_n_particles, axis=0)\n",
    "                \n",
    "\n",
    "    for i in range(covariance_post_selected.shape[0]):\n",
    "        for j in range(covariance_post_selected.shape[1]):\n",
    "            if i == j:\n",
    "                covariance_post_selected[i, j, :] = populations_post_selected[i, :] * (1 - populations_post_selected[i, :])\n",
    "            elif i > j:\n",
    "                covariance_post_selected[i, j, :] = covariance_post_selected[j, i, :]\n",
    "            else:\n",
    "                covariance_post_selected[i, j, :] -= populations_post_selected[i, :] * populations_post_selected[j, :]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    n3n4 = covariance_post_selected[readout_pair_2[0], readout_pair_2[1], :]\n",
    "    n2n4 = covariance_post_selected[readout_pair_1[1], readout_pair_2[1], :]\n",
    "    n2n3 = covariance_post_selected[readout_pair_1[1], readout_pair_2[0], :]\n",
    "    n1n4 = covariance_post_selected[readout_pair_1[0], readout_pair_2[1], :]\n",
    "    n1n3 = covariance_post_selected[readout_pair_1[0], readout_pair_2[0], :]\n",
    "    n1n2 = covariance_post_selected[readout_pair_1[0], readout_pair_1[1], :]\n",
    "\n",
    "\n",
    "    if plot_individual_terms:\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(10, 12), sharex=True)\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        n_terms = [n1n2, n1n3, n1n4, n2n3, n2n4, n3n4]\n",
    "\n",
    "        labels = []\n",
    "        for index_1 in readout_pair_1 + readout_pair_2:\n",
    "            for index_2 in readout_pair_1 + readout_pair_2:\n",
    "                if index_2 > index_1:\n",
    "                    labels.append(f'n{index_1+1}n{index_2+1}')\n",
    "\n",
    "\n",
    "\n",
    "        for ax, term, label in zip(axes, n_terms, labels):\n",
    "            ax.plot(times, term, 'o--')\n",
    "            ax.set_title(f'Population {label}')\n",
    "            ax.set_ylabel('Population')\n",
    "            ax.grid(True, alpha=0.3) \n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    covariance_sum = n1n3 - n1n4 - n2n3 + n2n4\n",
    "\n",
    "    return covariance_post_selected, covariance_sum\n",
    "\n",
    "\n",
    "def plot_post_selected_covariance_sum(measurement, covariance_sum, readout_pair_1, readout_pair_2, beamsplitter_time=None, ylim=None):\n",
    "   \n",
    "    times = measurement.get_times()\n",
    "\n",
    "    plt.plot(times, covariance_sum, 'o--')\n",
    "    plt.xlabel('Time (ns)')\n",
    "    plt.ylabel('Current Correlation')\n",
    "\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "\n",
    "    if beamsplitter_time is not None:\n",
    "        plt.axvline(beamsplitter_time, color='r', alpha=0.4, linestyle='--', label='Beamsplitter Time')\n",
    "\n",
    "    correlator_symbol = f'$\\\\langle j_{{{readout_pair_1[0]+1}{readout_pair_1[1]+1}}}j_{{{readout_pair_2[0]+1}{readout_pair_2[1]+1}}}\\\\rangle$ '\n",
    "    plt.title(f'Post-Selected Current Correlations {correlator_symbol} for 8 qubits')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2deab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_filename = {}\n",
    "\n",
    "# 9/24/25 - 8Q\n",
    "name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '09', '24', '16', '53', '27') # best\n",
    "name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_filename('2025', '09', '24', '16', '59', '42')\n",
    "\n",
    "\n",
    "# 9/26/25 - 8Q\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '09', '26', '15', '59', '52')\n",
    "# name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_filename('2025', '09', '26', '16', '58', '08')\n",
    "\n",
    "# 9/29/25 - 8Q\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_double_jump_correlations_filename('2025', '09', '29', '15', '40','31')\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '09', '29', '16', '06', '09')\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '09', '29', '16', '45', '51')\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_double_jump_correlations_filename('2025', '09', '29', '17', '38', '37')\n",
    "\n",
    "# 9/30/25 - 8Q\n",
    "# check population oscillations from this measurement\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_double_jump_correlations_filename('2025', '09', '30', '11', '43', '58')\n",
    "\n",
    "# 10/02/25 - 8Q\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '02', '11', '00', '43')\n",
    "# name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '02', '13', '24', '29')\n",
    "\n",
    "# 10/03/25 - 8Q\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_double_jump_correlations_filename('2025', '10', '03', '12', '51', '14')\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '03', '16', '51', '48')\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '03', '18', '06', '23')\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '03', '20', '37', '51')\n",
    "\n",
    "\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_double_jump_correlations_filename('2025', '10', '03', '20', '48', '53')\n",
    "\n",
    "# 10/04/25 - 8Q\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_double_jump_correlations_filename('2025', '10', '04', '14', '37', '49')\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '04', '14', '49', '41')\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '04', '17', '00', '35')\n",
    "\n",
    "# 10/06/25 - 8Q\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '06', '12', '25', '36')\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_double_jump_correlations_filename('2025', '10', '06', '14', '24', '30')\n",
    "# name_to_filename['4P8Q_1278'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '06', '15', '50', '31')\n",
    "# name_to_filename['4P8Q_1278'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '06', '16', '13', '24')\n",
    "# name_to_filename['4P8Q_1278'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '06', '16', '45', '45')\n",
    "\n",
    "# 10/07/25 - 8Q\n",
    "# name_to_filename['4P8Q_1278'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '07', '13', '06', '54') # resonant holes\n",
    "# name_to_filename['4P8Q_1278'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '07', '13', '10', '46') # off resonant holes\n",
    "\n",
    "# name_to_filename['4P8Q_test'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '07', '16', '38', '53') # test\n",
    "\n",
    "# 10/08/25 - 8Q\n",
    "# name_to_filename['4P8Q_1278'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '08', '12', '10', '34') # ramp near sweet spot \n",
    "\n",
    "# 10/09/25 - 8Q\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '09', '10', '53', '04') # ramp near sweet spot \n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_clean_filename('2025', '10', '09', '11', '08', '50') # ramp near sweet spot \n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '09', '11', '24', '13') # ramp near sweet spot \n",
    "name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_clean_filename('2025', '10', '09', '11', '21', '33') # ramp near sweet spot \n",
    "\n",
    "\n",
    "name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '09', '13', '08', '13') # ramp near sweet spot \n",
    "name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_clean_filename('2025', '10', '09', '14', '06', '28') # ramp near sweet spot \n",
    "name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '09', '15', '11', '43') # ramp near sweet spot \n",
    "name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_clean_filename('2025', '10', '09', '15', '15', '20') # ramp near sweet spot \n",
    "\n",
    "\n",
    "name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_clean_filename('2025', '10', '09', '15', '28', '54') # more shots \n",
    "name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_clean_filename('2025', '10', '09', '15', '49', '15') # more shots \n",
    "\n",
    "\n",
    "name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '09', '18', '28', '53') # ramp near sweet spot \n",
    "name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_clean_filename('2025', '10', '09', '18', '34', '07') # ramp near sweet spot \n",
    "\n",
    "\n",
    "name_to_filename['4P8Q_1254'] = generate_current_calibration_filename('2025', '10', '09', '18', '59', '20') # ramp near sweet spot \n",
    "\n",
    "\n",
    "# 10/10/25\n",
    "\n",
    "name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '10', '14', '27', '14') \n",
    "name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '10', '14', '32', '53') \n",
    "\n",
    "# testing various things\n",
    "name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '10', '21', '06', '57') \n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '10', '21', '11', '32') \n",
    "name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '10', '21', '25', '11') \n",
    "name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '10', '21', '35', '07') \n",
    "\n",
    "\n",
    "# 10/24/25\n",
    "name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '24', '14', '53', '35')\n",
    "\n",
    "\n",
    "# 10/27/25 \n",
    "# trying to optimize 12-54 correlations\n",
    "# name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '27', '13', '59', '30')\n",
    "\n",
    "name_to_filename['4P8Q_1254'] = generate_current_calibration_filename('2025', '10', '27', '17', '57', '08') \n",
    "\n",
    "\n",
    "# 10/28/25\n",
    "name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '28', '18', '42', '01')\n",
    "name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '28', '18', '45', '46')\n",
    "\n",
    "\n",
    "name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '28', '18', '58', '49')\n",
    "name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '28', '19', '02', '25')\n",
    "\n",
    "\n",
    "# 10/29/25\n",
    "\n",
    "# name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '29', '14', '49', '18')\n",
    "name_to_filename['4P8Q_2356'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '29', '14', '54', '20')\n",
    "\n",
    "\n",
    "name_to_filename['4P8Q_2345'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '29', '17', '07', '19')\n",
    "\n",
    "\n",
    "name_to_filename['4P8Q_2345'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '29', '17', '09', '39')\n",
    "\n",
    "\n",
    "# 10/30/25\n",
    "name_to_filename['4P8Q_2345'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '30', '12', '51', '43')\n",
    "\n",
    "# name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '30', '15', '17', '01') # this one's bad\n",
    "name_to_filename['4P8Q_1254'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '30', '15', '19', '34') # best 1245 so far\n",
    "\n",
    "\n",
    "name_to_filename['4P8Q_2365'] = generate_ramp_beamsplitter_correlations_filename('2025', '10', '30', '16', '32', '27')\n",
    "\n",
    "# 11/04/25\n",
    "name_to_filename['4P8Q_1234'] = generate_ramp_beamsplitter_correlations_filename('2025', '11', '04', '11', '19', '24') # high quality 1234\n",
    "\n",
    "\n",
    "name_to_measurement = {}\n",
    "for name in name_to_filename:\n",
    "    name_to_measurement[name] = RampOscillationShotsMeasurement(name_to_filename[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb4ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_even = '4P8Q_1234'\n",
    "# state_even = '4P8Q_1278'\n",
    "state_odd = '4P8Q_1254'\n",
    "\n",
    "measurement_even = name_to_measurement[state_even]\n",
    "measurement_odd = name_to_measurement[state_odd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a31e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot post selected data\n",
    "\n",
    "\n",
    "post_select = True\n",
    "plot_individual_terms = False\n",
    "\n",
    "rung_to_readout_pairs = {\n",
    "    2: [[0, 1], [2, 3]],\n",
    "    3: [[0, 1], [4, 3]],\n",
    "    4: [[0, 1], [4, 5]],\n",
    "    5: [[0, 1], [6, 5]],\n",
    "    6: [[0, 1], [6, 7]],\n",
    "}\n",
    "\n",
    "J_12 = 6.02*2*np.pi\n",
    "rung_to_coupling = {\n",
    "    2: 6.01*2*np.pi,\n",
    "    3: 6.23*2*np.pi,\n",
    "    4: 6.07*2*np.pi,\n",
    "    5: 5.83*2*np.pi,\n",
    "    6: 6.37*2*np.pi,\n",
    "}\n",
    "\n",
    "beamsplitter_offset = 5\n",
    "\n",
    "plot_rungs = [2,4,6]\n",
    "# plot_rungs = [3]\n",
    "# plot_rungs = [2, 3, 4, 5, 6]\n",
    "# plot_rungs = [2, 3, 4, 6]\n",
    "ylim = (-0.35, 0.35)\n",
    "\n",
    "correlations_data = []\n",
    "\n",
    "for rung in plot_rungs:\n",
    "    if not rung in rung_to_readout_pairs:\n",
    "        continue\n",
    "    readout_pair_1, readout_pair_2 = rung_to_readout_pairs[rung]\n",
    "\n",
    "    print(f'Rung {rung}:')\n",
    "\n",
    "    average_coupling = (J_12 + rung_to_coupling[rung])/2\n",
    "    beamsplitter_time = abs((np.pi/4)/(average_coupling))*1e3 + beamsplitter_offset  # in ns\n",
    "    print(f'beamsplitter time: {beamsplitter_time:.2f} ns')\n",
    "\n",
    "    print(rung_to_readout_pairs[rung])\n",
    "    if rung % 2 == 0:\n",
    "        measurement = measurement_even\n",
    "    else:\n",
    "        measurement = measurement_odd\n",
    "        \n",
    "    populations_post_selected, counts_n_particles, bitstrings_n_particles = post_select_counts(measurement, readout_pair_1, readout_pair_2, post_select=post_select)\n",
    "    covariance_post_selected, covariance_sum = get_post_selected_covariance(measurement, populations_post_selected, counts_n_particles, bitstrings_n_particles, readout_pair_1, readout_pair_2, plot_individual_terms=plot_individual_terms)\n",
    "    plot_post_selected_covariance_sum(measurement, covariance_sum, readout_pair_1, readout_pair_2, beamsplitter_time=beamsplitter_time, ylim=ylim)\n",
    "\n",
    "    # plot_select_counts(measurement, readout_pair_1, readout_pair_2, beamsplitter_time=beamsplitter_time, ylim=ylim, post_select=post_select, plot_individual_terms=plot_individual_terms)\n",
    "\n",
    "    current_correlation_index = np.argmin(np.abs(measurement.get_times() - beamsplitter_time))\n",
    "    current_correlation_value = covariance_sum[current_correlation_index]\n",
    "\n",
    "    print(f'Current correlation at beamsplitter time for rungs ({readout_pair_1[0]+1},{readout_pair_1[1]+1}) and ({readout_pair_2[0]+1},{readout_pair_2[1]+1}): {current_correlation_value:.4f}')\n",
    "    correlations_data.append(current_correlation_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab91ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(populations_post_selected[0, :], 'o--', label=f'Q{1}')\n",
    "plt.plot(populations_post_selected[1, :], 'o--', label=f'Q{2}')\n",
    "\n",
    "plt.xlabel('Time (ns)')\n",
    "plt.ylabel('Population')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "for rung in plot_rungs:\n",
    "    plt.plot(populations_post_selected[rung, :], 'o--', label=f'Q{rung+1}')\n",
    "    plt.plot(populations_post_selected[rung+1, :], 'o--', label=f'Q{rung+2}')\n",
    "\n",
    "    plt.xlabel('Time (ns)')\n",
    "    plt.ylabel('Population')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3677ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations_data = [0.18, -0.08, 0.06, -0.03, 0.08] # 9/24/25\n",
    "\n",
    "expected_correlations_5us = [0.185, -0.0787, 0.0787, -0.0519, 0.0779]\n",
    "expected_beamsplitter_correlations_5us = [0.144, -0.0723, 0.002, -0.041, 0.036]\n",
    "\n",
    "expected_correlations = [0.32, -0.19, 0.13, -0.10, 0.08]\n",
    "expected_beamsplitter_correlations = [0.34, -0.147, 0.096, -0.08, 0.09]\n",
    "\n",
    "distances = [1, 2, 3, 4, 5]\n",
    "distances_data = np.array(plot_rungs) - 1\n",
    "\n",
    "# plt.plot(distances, np.abs(expected_correlations), label='simulation')\n",
    "# plt.plot(distances, np.abs(expected_correlations_5us), label='simulation (5 $\\\\mu$s)')\n",
    "# plt.plot(distances, np.abs(expected_correlations), alpha=0)\n",
    "\n",
    "# plt.plot(distances, np.abs(expected_beamsplitter_correlations), label='beamsplitter simulation', linestyle='dotted', color='green')\n",
    "# plt.plot(distances, np.abs(expected_beamsplitter_correlations_5us), label='beamsplitter simulation (5 $\\\\mu$s)', linestyle='dotted', color='green')\n",
    "\n",
    "\n",
    "plt.plot(distances_data, np.abs(correlations_data), linestyle='', marker='o', color='blue', ms=8, label='magnitude')\n",
    "plt.plot(distances_data, np.abs(correlations_data), linestyle='dashed', color='blue', alpha=0.5)\n",
    "plt.plot(distances_data, (correlations_data), linestyle='', marker='x', color='red', ms=8, label='data')\n",
    "plt.plot(distances_data, (correlations_data), linestyle='dashed', color='red', alpha=0.5)\n",
    "\n",
    "\n",
    "# plt.xlabel('rung distance')\n",
    "plt.xticks(ticks=distances, labels=[f'{int(d)}' for d in distances])\n",
    "plt.xlabel('distance')\n",
    "plt.ylabel('Current Correlation')\n",
    "\n",
    "plt.grid()\n",
    "plt.title('Current Correlation vs Rung Distance')\n",
    "\n",
    "plt.ylim(-0.1, 0.3)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c90ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement = measurement_even\n",
    "measurement = measurement_odd\n",
    "\n",
    "counts = measurement.get_counts()\n",
    "times = measurement.get_times()\n",
    "\n",
    "plt.plot(times, np.sum(counts, axis=0), label='all counts')\n",
    "plt.plot(times, np.sum(counts_n_particles, axis=0), label='post-selected counts (4 particles)')\n",
    "plt.xlabel('Time (ns)')\n",
    "plt.ylabel('Counts')\n",
    "plt.legend()\n",
    "plt.title('Counts vs Time')\n",
    "\n",
    "plt.ylim(0, np.sum(counts, axis=0).max()*1.1)\n",
    "plt.show()\n",
    "\n",
    "print(np.sum(counts, axis=0)[0])\n",
    "print(np.sum(counts_n_particles, axis=0)[0])\n",
    "measurement = measurement_even\n",
    "measurement = measurement_odd\n",
    "print(np.sum(counts_n_particles, axis=0)[0]/np.sum(counts, axis=0)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe7f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get histogram of particle number\n",
    "counts = measurement.get_counts()\n",
    "\n",
    "num_qubits = measurement.get_num_qubits()\n",
    "particle_numbers = np.zeros((num_qubits+1, counts.shape[-1]))\n",
    "\n",
    "bitstrings = list(product([0,1], repeat=num_qubits))\n",
    "for i in range(len(bitstrings)):\n",
    "    num_particles = int(sum(bitstrings[i]))\n",
    "    particle_numbers[num_particles, :] += counts[i, :]\n",
    "\n",
    "print(sum(particle_numbers[n] for n in range(num_qubits+1)))\n",
    "\n",
    "print(particle_numbers[4,0])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(num_qubits+1), np.mean(particle_numbers, axis=-1)/np.sum(np.mean(particle_numbers, axis=-1)))\n",
    "plt.xlabel('Number of Particles')\n",
    "plt.ylabel('Average Percentage')\n",
    "plt.title('Histogram of Particle Numbers')\n",
    "plt.xticks(range(num_qubits+1))\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### check other rung correlations from the 1234 measurement that we know works\n",
    "\n",
    "measurement = name_to_measurement['4P8Q_1234']\n",
    "\n",
    "ylim = (-0.35, 0.35)\n",
    "measurement.plot_covariance_sum([0,1], [2,3])\n",
    "measurement.plot_covariance_sum([2,3], [4,5])\n",
    "measurement.plot_covariance_sum([4,5], [6,7])\n",
    "measurement.plot_covariance_sum([2,3], [6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67d2b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "### post selection on even distances\n",
    "\n",
    "readout_pairs_list = []\n",
    "readout_pairs_list.append([[0,1], [2,3]])\n",
    "readout_pairs_list.append([[2,3], [4,5]])\n",
    "readout_pairs_list.append([[4,5], [6,7]])\n",
    "\n",
    "readout_pairs_list.append([[0,1], [4,5]])\n",
    "readout_pairs_list.append([[2,3], [6,7]])\n",
    "\n",
    "\n",
    "measurement = name_to_measurement['4P8Q_1234']\n",
    "\n",
    "for i in range(len(readout_pairs_list)):\n",
    "    readout_pair_1, readout_pair_2 = readout_pairs_list[i]\n",
    "\n",
    "    print(f'Rung {rung}:')\n",
    "\n",
    "    average_coupling = (J_12 + rung_to_coupling[rung])/2\n",
    "    beamsplitter_time = abs((np.pi/4)/(average_coupling))*1e3 + beamsplitter_offset  # in ns\n",
    "    print(f'beamsplitter time: {beamsplitter_time:.2f} ns')\n",
    "\n",
    "          \n",
    "    populations_post_selected, counts_n_particles, bitstrings_n_particles = post_select_counts(measurement, readout_pair_1, readout_pair_2, post_select=post_select)\n",
    "    covariance_post_selected, covariance_sum = get_post_selected_covariance(measurement, populations_post_selected, counts_n_particles, bitstrings_n_particles, readout_pair_1, readout_pair_2, plot_individual_terms=plot_individual_terms)\n",
    "    plot_post_selected_covariance_sum(measurement, covariance_sum, readout_pair_1, readout_pair_2, beamsplitter_time=None, ylim=ylim)\n",
    "\n",
    "    # plot_select_counts(measurement, readout_pair_1, readout_pair_2, beamsplitter_time=beamsplitter_time, ylim=ylim, post_select=post_select, plot_individual_terms=plot_individual_terms)\n",
    "\n",
    "    current_correlation_index = np.argmin(np.abs(measurement.get_times() - beamsplitter_time))\n",
    "    current_correlation_value = covariance_sum[current_correlation_index]\n",
    "\n",
    "    print(f'Current correlation at beamsplitter time for rungs ({readout_pair_1[0]+1},{readout_pair_1[1]+1}) and ({readout_pair_2[0]+1},{readout_pair_2[1]+1}): {current_correlation_value:.4f}')\n",
    "    correlations_data.append(current_correlation_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb44fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### post selection on odd distances\n",
    "\n",
    "readout_pairs_list = []\n",
    "# readout_pairs_list.append([[0,1], [4,3]])\n",
    "# readout_pairs_list.append([[2,3], [6,5]])\n",
    "\n",
    "\n",
    "### this should be equivalent to the 1234 correlations\n",
    "# readout_pairs_list.append([[4,3], [6,5]])\n",
    "\n",
    "\n",
    "# try 2365 now\n",
    "\n",
    "# this should be equivalent to 1245\n",
    "readout_pairs_list.append([[1,2], [5,4]])\n",
    "\n",
    "# this should be equivalent to 1234\n",
    "# readout_pairs_list.append([[4,5], [6,7]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "measurement = name_to_measurement['4P8Q_2365']\n",
    "# measurement = name_to_measurement['4P8Q_2356']\n",
    "# measurement = name_to_measurement['4P8Q_1254']\n",
    "\n",
    "for i in range(len(readout_pairs_list)):\n",
    "    readout_pair_1, readout_pair_2 = readout_pairs_list[i]\n",
    "\n",
    "    print(f'Rung {rung}:')\n",
    "\n",
    "    average_coupling = (J_12 + rung_to_coupling[rung])/2\n",
    "    beamsplitter_time = abs((np.pi/4)/(average_coupling))*1e3 + beamsplitter_offset  # in ns\n",
    "    print(f'beamsplitter time: {beamsplitter_time:.2f} ns')\n",
    "\n",
    "          \n",
    "    populations_post_selected, counts_n_particles, bitstrings_n_particles = post_select_counts(measurement, readout_pair_1, readout_pair_2, post_select=post_select)\n",
    "    covariance_post_selected, covariance_sum = get_post_selected_covariance(measurement, populations_post_selected, counts_n_particles, bitstrings_n_particles, readout_pair_1, readout_pair_2, plot_individual_terms=plot_individual_terms)\n",
    "    plot_post_selected_covariance_sum(measurement, covariance_sum, readout_pair_1, readout_pair_2, beamsplitter_time=None, ylim=ylim)\n",
    "\n",
    "    # plot_select_counts(measurement, readout_pair_1, readout_pair_2, beamsplitter_time=beamsplitter_time, ylim=ylim, post_select=post_select, plot_individual_terms=plot_individual_terms)\n",
    "\n",
    "    current_correlation_index = np.argmin(np.abs(measurement.get_times() - beamsplitter_time))\n",
    "    current_correlation_value = covariance_sum[current_correlation_index]\n",
    "\n",
    "    print(f'Current correlation at beamsplitter time for rungs ({readout_pair_1[0]+1},{readout_pair_1[1]+1}) and ({readout_pair_2[0]+1},{readout_pair_2[1]+1}): {current_correlation_value:.4f}')\n",
    "    correlations_data.append(current_correlation_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fbcac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### post selection on odd distances\n",
    "\n",
    "readout_pairs_list = []\n",
    "\n",
    "# try 2345 now\n",
    "\n",
    "# these should be equivalent to 1234\n",
    "readout_pairs_list.append([[1,2], [3,4]])\n",
    "readout_pairs_list.append([[3,4], [5,6]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "measurement = name_to_measurement['4P8Q_2345']\n",
    "\n",
    "for i in range(len(readout_pairs_list)):\n",
    "    readout_pair_1, readout_pair_2 = readout_pairs_list[i]\n",
    "\n",
    "    print(f'Rung {rung}:')\n",
    "\n",
    "    average_coupling = (J_12 + rung_to_coupling[rung])/2\n",
    "    beamsplitter_time = abs((np.pi/4)/(average_coupling))*1e3 + beamsplitter_offset  # in ns\n",
    "    print(f'beamsplitter time: {beamsplitter_time:.2f} ns')\n",
    "\n",
    "          \n",
    "    populations_post_selected, counts_n_particles, bitstrings_n_particles = post_select_counts(measurement, readout_pair_1, readout_pair_2, post_select=post_select)\n",
    "    covariance_post_selected, covariance_sum = get_post_selected_covariance(measurement, populations_post_selected, counts_n_particles, bitstrings_n_particles, readout_pair_1, readout_pair_2, plot_individual_terms=plot_individual_terms)\n",
    "    plot_post_selected_covariance_sum(measurement, covariance_sum, readout_pair_1, readout_pair_2, beamsplitter_time=None, ylim=ylim)\n",
    "\n",
    "    # plot_select_counts(measurement, readout_pair_1, readout_pair_2, beamsplitter_time=beamsplitter_time, ylim=ylim, post_select=post_select, plot_individual_terms=plot_individual_terms)\n",
    "\n",
    "    current_correlation_index = np.argmin(np.abs(measurement.get_times() - beamsplitter_time))\n",
    "    current_correlation_value = covariance_sum[current_correlation_index]\n",
    "\n",
    "    print(f'Current correlation at beamsplitter time for rungs ({readout_pair_1[0]+1},{readout_pair_1[1]+1}) and ({readout_pair_2[0]+1},{readout_pair_2[1]+1}): {current_correlation_value:.4f}')\n",
    "    correlations_data.append(current_correlation_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
